{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4611d785",
   "metadata": {
    "cellId": "ljgngkf1q2qfcxp5ng1c"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "import os, time, cv2, sys, math\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as l\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import base64\n",
    "import operator\n",
    "\n",
    "from Utils.ADE20K_utils import *\n",
    "from Utils.images_utilities import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da189921",
   "metadata": {
    "cellId": "uo52fs3vujeyehrnhx4s6h"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "# from FC_DenseNet_Tiramisu import build_tiramisu\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9bd712",
   "metadata": {
    "cellId": "6lur3iuvt3hdlyf98bgxh"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "# Загрузка индекса с глобальной информацией о датасете\n",
    "DATASET_PATH = '/home/jupyter/mnt/datasets/ADE20K'\n",
    "index_file = '/ADE20K_2021_17_01/index_ade20k.pkl'\n",
    "with open('{}/{}'.format(DATASET_PATH, index_file), 'rb') as f:\n",
    "    index_ade20k = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2332dad5",
   "metadata": {
    "cellId": "61wjnpot4optre8lzd3lg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные были загружены.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Набор фото тренировки: 100%|██████████| 25248/25248 [00:00<00:00, 2805165.09it/s]\n",
      "Набор фото валидации: 100%|██████████| 2000/2000 [00:00<00:00, 2621440.00it/s]\n",
      "Набор фото тестирования: 100%|██████████| 316/316 [00:00<00:00, 1366391.82it/s]\n",
      "Набор сег. фото тренировки: 100%|██████████| 25248/25248 [00:00<00:00, 2710046.77it/s]\n",
      "Набор сег. фото валидации: 100%|██████████| 2000/2000 [00:00<00:00, 2707749.52it/s]\n",
      "Набор сег. фото тестирования: 100%|██████████| 316/316 [00:00<00:00, 1535805.40it/s]\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "\n",
    "# В данном коде идёт загрузка списков путей для дальнейшей обработки. \n",
    "# Для оптимизации иполнения был создан отдельный файл, в который закидываются строки.\n",
    "# Не хотел добавлять новых библиотек, cправился без Pandas, а зря.\n",
    "\n",
    "train = []\n",
    "train_seg = []\n",
    "val = []\n",
    "val_seg = []\n",
    "test = []\n",
    "test_seg = []\n",
    "\n",
    "file = './Data/file_list.txt'\n",
    "if os.path.exists(file):\n",
    "    with open(file, 'r') as f:\n",
    "        paths_list = f.read()\n",
    "        paths_list = list(paths_list.replace(\"'\", \"\").replace('[', '').replace(']', '').split(sep=\", \"))\n",
    "        for i in tqdm.tqdm(range(0, 25248), desc='Набор фото тренировки'):\n",
    "            train.append(paths_list[i])\n",
    "        for i in tqdm.tqdm(range(25248, 27248), desc='Набор фото валидации'):\n",
    "            val.append(paths_list[i])\n",
    "        for i in tqdm.tqdm(range(27248, 27564), desc='Набор фото тестирования'):\n",
    "            test.append(paths_list[i])\n",
    "        for i in tqdm.tqdm(range(27564, 52812), desc='Набор сег. фото тренировки'):\n",
    "            train_seg.append(paths_list[i])\n",
    "        for i in tqdm.tqdm(range(52812, 54812), desc='Набор сег. фото валидации'):\n",
    "            val_seg.append(paths_list[i])\n",
    "        for i in tqdm.tqdm(range(54812, 55128), desc='Набор сег. фото тестирования'):\n",
    "            test_seg.append(paths_list[i])\n",
    "        f.close()\n",
    "else:\n",
    "    for i in tqdm.tqdm(range(0, 27574), desc=\"Занесено пар: \"):\n",
    "        full_file_name = '{}/{}'.format(index_ade20k['folder'][i], index_ade20k['filename'][i])\n",
    "        try:\n",
    "            info = loadAde20K('{}/{}'.format(DATASET_PATH, full_file_name))\n",
    "            if 0 <= i <= 25257:\n",
    "                train.append(info['img_name'])\n",
    "                train_seg.append(info['segm_name'])\n",
    "            elif 25258 <= i <= 27257:\n",
    "                val.append(info['img_name'])\n",
    "                val_seg.append(info['segm_name'])\n",
    "            elif 27258 <= i <= 27573:\n",
    "                test.append(info['img_name'])\n",
    "                test_seg.append(info['segm_name'])\n",
    "        except KeyboardInterrupt:\n",
    "            print('ПРЕРЫВАЮ!')\n",
    "            break\n",
    "        except:\n",
    "            tqdm.tqdm.write('Ошибка на индексе'+str(i))\n",
    "\n",
    "    with open(file, 'w+') as f:\n",
    "        f.write(str(train + val + test + train_seg + val_seg + test_seg))\n",
    "        f.close()\n",
    "\n",
    "print('Данные были загружены.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457f71f1",
   "metadata": {
    "cellId": "6mp8fvl1yw4rfzzzry19c"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n",
    "def dense_block(input_tensor, block_num, num_layers, growth_rate):\n",
    "    concat_layers = [input_tensor]\n",
    "    x = input_tensor\n",
    "    for i in range(num_layers):\n",
    "        layer = l.BatchNormalization(name=f'bn_{block_num}_{i}')(x)\n",
    "        layer = l.ReLU(name=f'relu_{block_num}_{i}')(layer)\n",
    "        layer = l.Conv2D(growth_rate, (3, 3), padding='same', name=f'conv_{block_num}_{i}')(layer)\n",
    "        concat_layers.append(layer)\n",
    "        x = l.concatenate(concat_layers, axis=-1, name=f'concat_{block_num}_{i}')\n",
    "    return x\n",
    "\n",
    "def transition_down(input_tensor, block_num):\n",
    "    x = l.BatchNormalization(name=f'bn_td_{block_num}')(input_tensor)\n",
    "    x = l.ReLU(name=f'relu_td_{block_num}')(x)\n",
    "    x = l.Conv2D(int(x.shape[-1]) // 2, (1, 1), name=f'conv_td_{block_num}')(x)\n",
    "    x = l.MaxPooling2D((2, 2), strides=(2, 2), name=f'maxpool_td_{block_num}')(x)\n",
    "    return x\n",
    "\n",
    "def build_tiramisu(input_shape, num_classes, num_blocks=5, num_layers_per_block=4, growth_rate=16):\n",
    "    input_layer = l.Input(shape=input_shape, name='input')\n",
    "    x = input_layer\n",
    "    \n",
    "    skip_connections = []\n",
    "\n",
    "    for i in range(num_blocks):\n",
    "        x = dense_block(x, i+1, num_layers_per_block, growth_rate)\n",
    "        skip_connections.append(x)\n",
    "        if i != num_blocks - 1:\n",
    "            x = transition_down(x, i+1)\n",
    "\n",
    "    x = dense_block(x, num_blocks+1, num_layers_per_block, growth_rate)\n",
    "\n",
    "    for i in range(num_blocks - 1, -1, -1):\n",
    "        x = l.Conv2DTranspose(int(skip_connections[i].shape[-1]) // 2, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "        x = tf.image.resize(x, skip_connections[i].shape[1:3])\n",
    "        x = l.concatenate([x, skip_connections[i]], axis=-1)\n",
    "        x = dense_block(x, num_blocks+2+i, num_layers_per_block, growth_rate)\n",
    "\n",
    "    output_layer = l.Conv2D(num_classes, (1, 1), activation='softmax', name='output')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dfa5629",
   "metadata": {
    "cellId": "w8kh4kfts4barr7bgy0t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настройка процедуры обучения...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 20:42:06.445464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jupyter/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-08-15 20:42:06.445519: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-15 20:42:06.445543: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (m2-e58e1947-b749-4503-9869-22f2a47d758b): /proc/driver/nvidia/version does not exist\n",
      "2023-08-15 20:42:06.445808: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "\n",
    "print('Настройка процедуры обучения...')\n",
    "\n",
    "network = build_tiramisu((360, 640, 3), 3688)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d694859d",
   "metadata": {
    "cellId": "o91rcvjoh8mxt9devmja8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запущен процесс загрузки картинок из .csv файла...\n",
      "Успешно завершено!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Декодирую...: 100%|██████████| 25248/25248 [02:55<00:00, 144.19it/s]\n",
      "Декодирую...: 100%|██████████| 2000/2000 [00:14<00:00, 136.03it/s]\n",
      "Декодирую...: 100%|██████████| 316/316 [00:02<00:00, 134.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network, labels=output))\n",
    "# class_names_string = str(index_ade20k['objectnames']).replace('[', '').replace(']', '').replace(\"'\", \"\")\n",
    "\n",
    "# Инициализация параметров\n",
    "epochs = 25\n",
    "is_training = True\n",
    "cont_training = False\n",
    "class_names_list = index_ade20k['objectnames']\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, decay=0.995)\n",
    "\n",
    "# Создание чекпоинтов модели\n",
    "checkp_path = './Checkpoints/'\n",
    "checkpoint = tf.train.Checkpoint(network)\n",
    "save_path = checkpoint.save(checkp_path)\n",
    "if cont_training or not is_training:\n",
    "    print('Загрузка чекпоинта...')\n",
    "    checkpoint.restore(save_path)\n",
    "\n",
    "\n",
    "\n",
    "pd_file_path_tr = './Data/images_train.csv'\n",
    "pd_file_path_v = './Data/images_val.csv'\n",
    "pd_file_path_t = './Data/images_test.csv'\n",
    "if not os.path.exists(pd_file_path_tr) and not os.path.exists(pd_file_path_v) and not os.path.exists(pd_file_path_t):\n",
    "    \n",
    "    print('Запущен процесс загрузки и кодирования картинок для последующего формирования .csv файлов...')\n",
    "    \n",
    "    target_size=(640, 360)\n",
    "    input_train_images_b64, output_train_images_b64 = [], []\n",
    "    input_val_images_b64, output_val_images_b64 = [], []\n",
    "    input_test_images_b64, output_test_images_b64 = [], []\n",
    "    \n",
    "    input_train_images_b64, output_train_images_b64 = image_to_base64(load_images(train, train_seg, target_size))\n",
    "    del train, train_seg\n",
    "    input_val_images_b64, output_val_images_b64 = image_to_base64(load_images(val, val_seg, target_size))\n",
    "    del val, val_seg\n",
    "    input_test_images_b64, output_test_images_b64 = image_to_base64(load_images(test, test_seg, target_size))\n",
    "    del test, test_seg\n",
    "    \n",
    "    data_train = {'inp_tr_img_b64': input_train_images_b64, 'outp_tr_img_b64': output_train_images_b64}\n",
    "    data_val = {'inp_val_img_b64': input_val_images_b64, 'outp_val_img_b64': output_val_images_b64}\n",
    "    data_test = {'inp_test_img_b64': input_test_images_b64, 'outp_test_img_b64': output_test_images_b64}\n",
    "    \n",
    "    df_train = pd.DataFrame(data_train)\n",
    "    df_val = pd.DataFrame(data_val)\n",
    "    df_test = pd.DataFrame(data_test)\n",
    "    \n",
    "    df_train.to_csv(pd_file_path_tr, index=False)\n",
    "    df_val.to_csv(pd_file_path_v, index=False)\n",
    "    df_test.to_csv(pd_file_path_t, index=False)\n",
    "    del input_train_images_b64, output_train_images_b64, input_val_images_b64, output_val_images_b64, input_test_images_b64, output_test_images_b64\n",
    "    del df_train, df_val, df_test\n",
    "    print('Процес успешно завершён!')\n",
    "    \n",
    "\n",
    "print('Запущен процесс загрузки картинок из .csv файла...')\n",
    "df_train = pd.read_csv(pd_file_path_tr)\n",
    "df_val = pd.read_csv(pd_file_path_v)\n",
    "df_test = pd.read_csv(pd_file_path_t)\n",
    "    \n",
    "input_train_images, output_train_images = base64_to_img(df_train['inp_tr_img_b64'], df_train['outp_tr_img_b64'])\n",
    "input_val_images, output_val_images = base64_to_img(df_val['inp_val_img_b64'], df_val['outp_val_img_b64'])\n",
    "input_test_images, output_test_images = base64_to_img(df_test['inp_test_img_b64'], df_test['outp_test_img_b64'])\n",
    "print('Успешно завершено!')\n",
    "del df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99e4e57",
   "metadata": {
    "cellId": "oftvxwm4zqlx71vxv04iz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Нормализация...: 100%|██████████| 10/10 [00:00<00:00, 179.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "images_norm = img_normilize(input_train_images[:10])\n",
    "del input_train_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea10a755",
   "metadata": {
    "cellId": "1goodnfeqjxk4xtajsm1s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение класса для пикселя (393, 167): [142  68  80]\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "mask_path = '/home/jupyter/mnt/datasets/ADE20K/ADE20K_2021_17_01/images/ADE/training/cultural/armory/ADE_train_00001593_seg.png'\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Получение значения класса для конкретного пикселя (x, y)\n",
    "x = 393  # Координата x пикселя\n",
    "y = 167  # Координата y пикселя\n",
    "\n",
    "class_id = mask[y, x]\n",
    "\n",
    "print(f\"Значение класса для пикселя ({x}, {y}): {class_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dff1438",
   "metadata": {
    "cellId": "fswybkdhte5iyu260pqoj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 20:47:53.054949: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-08-15 20:47:53.054997: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2023-08-15 20:47:53.055376: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-08-15 20:47:53.400388: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640, 3)\n",
      "(360, 640, 3)\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:788 train_step\n        loss = self.compiled_loss(\n    /usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.8/dist-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.8/dist-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.8/dist-packages/keras/losses.py:1665 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.8/dist-packages/keras/backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 360, 640, 3) and (None, 360, 640, 3688) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77223bd0a012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# network.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:788 train_step\n        loss = self.compiled_loss(\n    /usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.8/dist-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.8/dist-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.8/dist-packages/keras/losses.py:1665 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.8/dist-packages/keras/backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 360, 640, 3) and (None, 360, 640, 3688) are incompatible\n"
     ]
    }
   ],
   "source": [
    "#!c1.32\n",
    "log_dir = './Logs/'\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            embeddings_freq=1,)\n",
    "    ]\n",
    "\n",
    "images_norm = np.array(images_norm)\n",
    "masks = np.array(output_train_images[:10])\n",
    "print(images_norm[1].shape)\n",
    "print(masks[1].shape)\n",
    "\n",
    "network.compile(optimizer = opt,\n",
    "               loss = loss)\n",
    "\n",
    "# network.summary()\n",
    "network.fit(images_norm, masks, epochs=epochs, batch_size=64, shuffle=True, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e37e2",
   "metadata": {
    "cellId": "ul085e9o3cav5zxymijusi"
   },
   "outputs": [],
   "source": [
    "#!c1.32\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "26af0921-db43-4576-9031-5393ad7d3a04",
  "notebookPath": "ImageAI/Backend/Background_deleter_OLD/models_creator.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
